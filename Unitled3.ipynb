{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3411c2bd-3f08-4fa0-b59c-b493e9257b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import tempfile\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from skimage import io\n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e40e0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MRI_FOLDER =\"./data/dMRI_Pre\"\n",
    "MASK_FOLDER =\"./data/RK_Pre\"\n",
    "\n",
    "TRAIN_SPLIT_PERC = 0.65\n",
    "TEST_SPLIT_PERC = 0.20\n",
    "VAL_SPLIT_PERC = 1 - TEST_SPLIT_PERC - TRAIN_SPLIT_PERC\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "\n",
    "images = sorted(glob(os.path.join(MRI_FOLDER, \"*.jpg\")))\n",
    "segs = sorted(glob(os.path.join(MASK_FOLDER, \"*.jpg\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3444e90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n",
      "(135, 3)\n",
      "{'train': (87, 3), 'test': (21, 3), 'ValidLoad': (27, 3), 'orig': 135, 'TrainNum': 87, 'ValidNum': 114}\n",
      "DataLoader Completed\n"
     ]
    }
   ],
   "source": [
    "MRIdata = pd.DataFrame({\"dMRIpath\": images,'MASKpath':segs})\n",
    "\n",
    "def get_Wholes_NoWholes(dMRIpath):\n",
    "    value = np.max(cv2.imread(dMRIpath))\n",
    "    if value > 0 : \n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "print(\"Here\")  \n",
    "MRIdata['mask'] = MRIdata['MASKpath'].apply(lambda x: get_Wholes_NoWholes(x))\n",
    "#MRIdata['MASKpath'] = MRIdata['MASKpath'].apply(lambda x: str(x))\n",
    "print(MRIdata.shape)\n",
    "############################################################################\n",
    "\n",
    "#Prepare Data Loaders\n",
    "image_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(), ])\n",
    "\n",
    "mask_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(), ])\n",
    "#--------------------------------------------------------------------------\n",
    "#Normalize the data\n",
    "def NormalizeData(img, mask):\n",
    "    img = img / 255.\n",
    "    mask = mask / 255.\n",
    "    mask[mask > 0.5] = 1.0\n",
    "    mask[mask <= 0.5] = 0.0\n",
    "    \n",
    "    return (img, mask)\n",
    "#--------------------------------------------------------------------------\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df= MRIdata, \n",
    "                 NormalizeData = NormalizeData, \n",
    "                 image_transform=image_transform, mask_transform=mask_transform):\n",
    "        self.df = df\n",
    "        self.image_transform = image_transform\n",
    "        self.mask_transform = mask_transform\n",
    "        self.NormalizeData= NormalizeData\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        MRIpath = self.df.loc[idx, 'dMRIpath']\n",
    "        MASKpath = self.df.loc[idx, 'MASKpath']\n",
    "\n",
    "        mri = cv2.imread(MRIpath)\n",
    "        mri = cv2.cvtColor(mri, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(MASKpath)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        mri, mask = self.NormalizeData(mri, mask)\n",
    "\n",
    "        if self.image_transform:\n",
    "            mri = self.image_transform(mri).float()\n",
    "\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)\n",
    "        return mri, mask\n",
    "    \n",
    "################################################################\n",
    "\n",
    "def prepare_loaders(df= MRIdata,\n",
    "                    TrainNum= int(MRIdata.shape[0] * .6), \n",
    "                    ValidNum= int(MRIdata.shape[0] * .8), \n",
    "                    bs = 32):\n",
    "#     shuffled = df.sample(frac=1) # TODO TM SHOULD WE SHUFFLE HERE \n",
    "    shuffled = df\n",
    "    Train = shuffled[:TrainNum].reset_index(drop=True)\n",
    "    Valid = shuffled[TrainNum : ValidNum].reset_index(drop=True)    \n",
    "    Test  = shuffled[ValidNum:].reset_index(drop=True)\n",
    "    print({\"train\":Train.shape, \"test\":Test.shape, \"ValidLoad\":Valid.shape, \"orig\": MRIdata.shape[0], \"TrainNum\": TrainNum, \"ValidNum\": ValidNum})\n",
    "\n",
    "    TrainSet = MyDataset(df = Train)\n",
    "    ValidSet = MyDataset(df = Valid)\n",
    "    TestSet = MyDataset(df = Test)\n",
    "\n",
    "    TrainLoad = DataLoader(TrainSet, batch_size = bs, shuffle = True)\n",
    "    ValidLoad = DataLoader(ValidSet, batch_size = bs, shuffle = False)\n",
    "    TestLoad = DataLoader(TestSet, batch_size = 4, shuffle = True)\n",
    "    \n",
    "    print(\"DataLoader Completed\")\n",
    "    \n",
    "    return TrainLoad, ValidLoad, TestLoad\n",
    "#--------------------------------------------------------------------------\n",
    "TrainLoad, ValidLoad, TestLoad = prepare_loaders(df= MRIdata,\n",
    "                                                            TrainNum= int(MRIdata.shape[0] * TRAIN_SPLIT_PERC), \n",
    "                                                            ValidNum= int(MRIdata.shape[0] * (TRAIN_SPLIT_PERC + TEST_SPLIT_PERC)), \n",
    "                                                            bs = TRAIN_BATCH_SIZE)\n",
    "\n",
    "data = next(iter(TrainLoad))\n",
    "# dataTe = next(iter(TestLoad))\n",
    "# dataVa = next(iter(ValidLoad))\n",
    "#data[0].shape, data[1].shape\n",
    "# print({\"train\":data, \"test\":dataTe, \"ValidLoad\":dataVa})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "680b2010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO GPU: Using CPU\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#------From Here We Build the UNet Model\n",
    "device = torch.device(\"cuda:0\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU - {}\\n\".format(torch.cuda.get_device_name()))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"NO GPU: Using CPU\")\n",
    "print(device)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, inputs = 3, middles = 64, outs = 64):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(inputs, middles, 3, 1, 1)\n",
    "        self.conv2 = nn.Conv2d(middles, outs, 3, 1, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn = nn.BatchNorm2d(outs)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "    def forward(self, x):       \n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.bn(self.conv2(x)))    \n",
    "        return self.pool(x), x\n",
    " \n",
    "###################################################################\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "\n",
    "        self.en1 = Block(3, 64, 64)\n",
    "        self.en2 = Block(64, 128, 128)\n",
    "        self.en3 = Block(128, 256, 256)\n",
    "        self.en4 = Block(256, 512, 512)\n",
    "        self.en5 = Block(512, 1024, 512)\n",
    "        \n",
    "        self.upsample4 = nn.ConvTranspose2d(512, 512, 2, stride = 2)\n",
    "        self.de4 = Block(1024, 512, 256)\n",
    "        \n",
    "        self.upsample3 = nn.ConvTranspose2d(256, 256, 2, stride = 2)\n",
    "        self.de3 = Block(512, 256, 128)\n",
    "        \n",
    "        self.upsample2 = nn.ConvTranspose2d(128, 128, 2, stride = 2)\n",
    "        self.de2 = Block(256, 128, 64)\n",
    "        \n",
    "        self.upsample1 = nn.ConvTranspose2d(64, 64, 2, stride = 2)\n",
    "        self.de1 = Block(128, 64, 64)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, 1, kernel_size=1, stride = 1, padding = 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: [bs, 3, 256, 256]\n",
    "        \n",
    "        x, e1 = self.en1(x)\n",
    "        # x: [bs, 64, 128, 128]\n",
    "        # e1: [bs, 64, 256, 256]\n",
    "        \n",
    "        x, e2 = self.en2(x)\n",
    "        # x: [bs, 128, 64, 64]\n",
    "        # e2: [bs, 128, 128, 128]\n",
    "        \n",
    "        x, e3 = self.en3(x)\n",
    "        # x: [bs, 256, 32, 32]\n",
    "        # e3: [bs, 256, 64, 64]\n",
    "        \n",
    "        x, e4 = self.en4(x)\n",
    "        # x: [bs, 512, 16, 16]\n",
    "        # e4: [bs, 512, 32, 32]\n",
    "        \n",
    "        _, x = self.en5(x)\n",
    "        # x: [bs, 512, 16, 16]\n",
    "        \n",
    "        x = self.upsample4(x)\n",
    "        # x: [bs, 512, 32, 32]\n",
    "        x = torch.cat([x, e4], dim=1)\n",
    "        # x: [bs, 1024, 32, 32]\n",
    "        _,  x = self.de4(x)\n",
    "        # x: [bs, 256, 32, 32]\n",
    "        \n",
    "        x = self.upsample3(x)\n",
    "        # x: [bs, 256, 64, 64]\n",
    "        x = torch.cat([x, e3], dim=1)\n",
    "        # x: [bs, 512, 64, 64]\n",
    "        _, x = self.de3(x)\n",
    "        # x: [bs, 128, 64, 64]\n",
    "        \n",
    "        x = self.upsample2(x)\n",
    "        # x: [bs, 128, 128, 128]\n",
    "        x = torch.cat([x, e2], dim=1)\n",
    "        # x: [bs, 256, 128, 128]\n",
    "        _, x = self.de2(x)\n",
    "        # x: [bs, 64, 128, 128]\n",
    "        \n",
    "        x = self.upsample1(x)\n",
    "        # x: [bs, 64, 256, 256]\n",
    "        x = torch.cat([x, e1], dim=1)\n",
    "        # x: [bs, 128, 256,256, 256\n",
    "        _, x = self.de1(x)\n",
    "        # x: [bs, 64, 256, 256]\n",
    "        \n",
    "        x = self.conv_last(x)\n",
    "       \n",
    "        return x\n",
    "          \n",
    "model = UNet().to(device)\n",
    "#model\n",
    "##########################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8fce4177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------Define Loss and Optimizer\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# loss_fn = nn.BCELoss().to(device)\n",
    "loss_fn = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), )\n",
    "\n",
    "# Scheduler\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max = 200,eta_min = 1e-6)\n",
    "\n",
    "##############################################################=======train_one_epoch\n",
    "def train_one_epoch(model = model, \n",
    "                    dataloader = TrainLoad, \n",
    "                    loss_fn = loss_fn, \n",
    "                    optimizer = optimizer,\n",
    "                    scheduler = None,\n",
    "                    device = device, \n",
    "                    epoch = 1):\n",
    "    model.train() \n",
    "    train_loss, dataset_size = 0,  0\n",
    "    \n",
    "    bar = tqdm(dataloader, total = len(dataloader))\n",
    "    tp_l, fp_l, fn_l, tn_l = [], [], [], []\n",
    "    \n",
    "    for data in bar:\n",
    "        x = data[0].to(device)     \n",
    "        y_true = data[1].to(device) \n",
    "        y_pred = model(x)          \n",
    "        \n",
    "        loss = loss_fn(y_pred, y_true)\n",
    "        \n",
    "        pred_mask = (y_pred > 0.5).float()\n",
    "        btp, bfp, bfn, btn = smp.metrics.get_stats(pred_mask.long(), y_true.long(), mode=\"binary\")\n",
    "\n",
    "        # \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # train_epoch_loss\n",
    "        bs = x.shape[0]\n",
    "        dataset_size += bs\n",
    "        train_loss += (loss.item() * bs)\n",
    "        train_epoch_loss = train_loss / dataset_size\n",
    "        \n",
    "        tp_l.append(btp)\n",
    "        fp_l.append(bfp)\n",
    "        fn_l.append(bfn)\n",
    "        tn_l.append(btn)\n",
    "        \n",
    "        tp = torch.cat(tp_l)\n",
    "        fp = torch.cat(fp_l)\n",
    "        fn = torch.cat(fn_l)\n",
    "        tn = torch.cat(tn_l)\n",
    "        \n",
    "        recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro\")\n",
    "        precision = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\")\n",
    "        \n",
    "        f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")\n",
    "        accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")\n",
    "        \n",
    "        # per image IoU means that we first calculate IoU score for each image \n",
    "        # and then compute mean over these scores\n",
    "        per_image_iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro-imagewise\")\n",
    "        \n",
    "        # dataset IoU means that we aggregate intersection and union over whole dataset\n",
    "        # and then compute IoU score. The difference between dataset_iou and per_image_iou scores\n",
    "        # in this particular case will not be much, however for dataset \n",
    "        # with \"empty\" images (images without target class) a large gap could be observed. \n",
    "        # Empty images influence a lot on per_image_iou and much less on dataset_iou.\n",
    "        dataset_iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")\n",
    "\n",
    "        bar.set_description(f\"EP:{epoch} | TL:{train_epoch_loss:.3e} | ACC: {accuracy:.2f} | F1: {f1_score:.3f} \")\n",
    "        \n",
    "    metrics =  dict()\n",
    "    \n",
    "    metrics['f1_score'] = f1_score.detach().cpu().item()\n",
    "    metrics['accuracy'] = accuracy.detach().cpu().item()\n",
    "    \n",
    "    metrics['recall'] = recall.detach().cpu().item()\n",
    "    metrics['precision'] = precision.detach().cpu().item()\n",
    "    \n",
    "    metrics['dataset_iou'] = dataset_iou.detach().cpu().item()\n",
    "    metrics['per_iou'] = per_image_iou.detach().cpu().item()\n",
    "    \n",
    "    metrics['loss'] = train_epoch_loss\n",
    "\n",
    "    return metrics\n",
    "\n",
    "###################################################################################-------run one_epoch\n",
    "\n",
    "@torch.no_grad()\n",
    "def valid_one_epoch(model = model, \n",
    "                    dataloader = ValidLoad, \n",
    "                    loss_fn = loss_fn,\n",
    "                    device = device, \n",
    "                    epoch = 0):\n",
    "    model.eval() \n",
    "    valid_loss, dataset_size = 0,  0\n",
    "    bar = tqdm(dataloader, total = len(dataloader))\n",
    "    tp_l, fp_l, fn_l, tn_l = [], [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in bar:\n",
    "            x = data[0].to(device)     \n",
    "            y_true = data[1].to(device) \n",
    "            y_pred = model(x)        \n",
    "            \n",
    "            loss = loss_fn(y_pred, y_true)\n",
    "            \n",
    "            pred_mask = (y_pred > 0.5).float()\n",
    "            btp, bfp, bfn, btn = smp.metrics.get_stats(pred_mask.long(), y_true.long(), mode=\"binary\")\n",
    "\n",
    "            tp_l.append(btp)\n",
    "            fp_l.append(bfp)\n",
    "            fn_l.append(bfn)\n",
    "            tn_l.append(btn)\n",
    "\n",
    "            tp = torch.cat(tp_l)\n",
    "            fp = torch.cat(fp_l)\n",
    "            fn = torch.cat(fn_l)\n",
    "            tn = torch.cat(tn_l)\n",
    "\n",
    "            recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro\")\n",
    "            precision = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\")\n",
    "\n",
    "            f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")\n",
    "            accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")\n",
    "\n",
    "            # per image IoU means that we first calculate IoU score for each image \n",
    "            # and then compute mean over these scores\n",
    "            per_image_iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro-imagewise\")\n",
    "\n",
    "            # dataset IoU means that we aggregate intersection and union over whole dataset\n",
    "            # and then compute IoU score. The difference between dataset_iou and per_image_iou scores\n",
    "            # in this particular case will not be much, however for dataset \n",
    "            # with \"empty\" images (images without target class) a large gap could be observed. \n",
    "            # Empty images influence a lot on per_image_iou and much less on dataset_iou.\n",
    "            dataset_iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")\n",
    "\n",
    "            # valid_epoch_loss \n",
    "            bs = x.shape[0]\n",
    "            dataset_size += bs\n",
    "            valid_loss += (loss.item() * bs)\n",
    "            valid_epoch_loss = valid_loss / dataset_size\n",
    "\n",
    "            bar.set_description(f\"EP:{epoch} | VL:{valid_epoch_loss:.3e} | ACC: {accuracy:.2f} | F1: {f1_score:.3f} \")\n",
    "\n",
    "    metrics =  dict()\n",
    "    \n",
    "    metrics['f1_score'] = f1_score.detach().cpu().item()\n",
    "    metrics['accuracy'] = accuracy.detach().cpu().item()\n",
    "    \n",
    "    metrics['recall'] = recall.detach().cpu().item()\n",
    "    metrics['precision'] = precision.detach().cpu().item()\n",
    "    \n",
    "    metrics['dataset_iou'] = dataset_iou.detach().cpu().item()\n",
    "    metrics['per_iou'] = per_image_iou.detach().cpu().item()\n",
    "    \n",
    "    metrics['loss'] = valid_epoch_loss\n",
    "\n",
    "    return metrics\n",
    "##########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a27771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "\n",
    "def run_training(model = model, \n",
    "                 loss_fn = loss_fn, \n",
    "                 TrainLoad = TrainLoad,\n",
    "                 ValidLoad = ValidLoad,\n",
    "                 optimizer = optimizer, \n",
    "                 device = device, \n",
    "                 n_epochs=100, \n",
    "                 early_stop = 20,\n",
    "                 scheduler = None):\n",
    "\n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    lowest_epoch, lowest_loss = np.inf, np.inf\n",
    "    \n",
    "    train_history, valid_history = [],  []\n",
    "    train_recalls, valid_recalls = [],  []\n",
    "    \n",
    "    train_pres, valid_pres = [],  []\n",
    "    train_accs, valid_accs = [],  []\n",
    "    \n",
    "    train_f1s, valid_f1s = [],  []\n",
    "    \n",
    "    train_per_ious, valid_per_ious = [], []\n",
    "    train_dataset_ious, valid_dataset_ious = [], []\n",
    "    \n",
    "    print_iter = 5\n",
    "\n",
    "    best_score = 0\n",
    "    best_model = \"None\"\n",
    "\n",
    "    for epoch in range(0, n_epochs):\n",
    "        gc.collect()\n",
    "\n",
    "        train_metrics = train_one_epoch(model= model,\n",
    "                                       dataloader = TrainLoad,\n",
    "                                       optimizer = optimizer,\n",
    "                                       scheduler = scheduler,\n",
    "                                       device = device,\n",
    "                                       epoch = epoch + 1\n",
    "                                       )\n",
    "        \n",
    "        valid_metrics = valid_one_epoch(model,\n",
    "                                       dataloader = ValidLoad,\n",
    "                                       device = device,\n",
    "                                       epoch = epoch + 1)\n",
    "        \n",
    "        \n",
    "        train_history += [train_metrics['loss']]\n",
    "        valid_history += [valid_metrics['loss']]\n",
    "        \n",
    "        train_recalls += [train_metrics['recall']]\n",
    "        valid_recalls += [valid_metrics['recall']]\n",
    "        \n",
    "        train_pres += [train_metrics['precision']]\n",
    "        valid_pres += [valid_metrics['precision']]\n",
    "        \n",
    "        train_accs += [train_metrics['accuracy']]\n",
    "        valid_accs += [valid_metrics['accuracy']]\n",
    "        \n",
    "        train_f1s += [train_metrics['f1_score']]\n",
    "        valid_f1s += [valid_metrics['f1_score']]\n",
    "        \n",
    "        train_per_ious += [train_metrics['per_iou']]\n",
    "        valid_per_ious += [valid_metrics['per_iou']]\n",
    "        \n",
    "        train_dataset_ious += [train_metrics['dataset_iou']]\n",
    "        valid_dataset_ious += [valid_metrics['dataset_iou']]\n",
    "        \n",
    "        \n",
    "        print()\n",
    "        if (epoch + 1) % print_iter == 0:\n",
    "            print(f\"Epoch:{epoch + 1}|TL:{train_metrics['loss']:.3e}|VL:{valid_metrics['loss']:.3e}|F1:{valid_metrics['f1_score']:.4f}|Dataset IOU:{valid_metrics['dataset_iou']:.4f}|Per Img IOU:{valid_metrics['per_iou']:.4f}|\")\n",
    "            print()\n",
    "            \n",
    "        if best_score < valid_metrics['f1_score']:\n",
    "            print(f\"Validation F1 Improved({best_score:.2f}) --> ({ valid_metrics['f1_score']:.2f})\")\n",
    "            best_model = model\n",
    "            best_score = valid_metrics['f1_score']\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            PATH2 =  f\"model_f1.bin\"\n",
    "            torch.save(model.state_dict(), PATH2)\n",
    "            print(f\"Better_F1_Model Saved\")\n",
    "            print()\n",
    "\n",
    "        if valid_metrics['loss']< lowest_loss:\n",
    "            print(f\"Validation Loss Improved({lowest_loss:.4e}) --> ({ valid_metrics['loss']:.4e})\")\n",
    "            lowest_loss = valid_metrics['loss']\n",
    "            lowest_epoch = epoch\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = f\"model.bin\"\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            print(f\"Better Loss Model Saved\")\n",
    "            print()\n",
    "        else:\n",
    "            if early_stop > 0 and lowest_epoch + early_stop < epoch + 1:\n",
    "                print(\"no improvement\") \n",
    "                break\n",
    "                \n",
    "    print()\n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best Loss: %.4e at %d th Epoch\" % (lowest_loss, lowest_epoch))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(torch.load('./model_f1.bin'))\n",
    "\n",
    "    result = dict()\n",
    "    result[\"Train Loss\"] = train_history\n",
    "    result[\"Valid Loss\"] = valid_history\n",
    "    \n",
    "    result[\"Train Recall\"] = train_recalls\n",
    "    result[\"Valid Recall\"] = valid_recalls\n",
    "    \n",
    "    result[\"Train Precision\"] = train_pres\n",
    "    result[\"Valid Precision\"] = valid_pres\n",
    "    \n",
    "    result[\"Train Accuracy\"] = train_accs\n",
    "    result[\"Valid Accuracy\"] = valid_accs\n",
    "    \n",
    "    result[\"Train F1 Score\"] = train_f1s\n",
    "    result[\"Valid F1 Score\"] = valid_f1s\n",
    "    \n",
    "    result[\"Train per Image IOU\"] = train_per_ious\n",
    "    result[\"Valid per Image IOU\"] = valid_per_ious\n",
    "    \n",
    "    result[\"Train Dataset IOU\"] = train_dataset_ious\n",
    "    result[\"Valid Dataset IOU\"] = valid_dataset_ious\n",
    "    \n",
    "    return model, result\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40e6450",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Run Training\n",
    "model, result = run_training(model = model, \n",
    "                             loss_fn = loss_fn, \n",
    "                             optimizer = optimizer, \n",
    "                             device = device, \n",
    "                             scheduler = scheduler,\n",
    "                             n_epochs = 10)\n",
    "\n",
    "torch.save(model.state_dict(), \"/home1/cliog/MLProject/Test1/OLD_FILE/MyModel.pth\")\n",
    "FILE_NAME = \"/home1/cliog/MLProject/Test1/OLD_FILE/Result.json\"\n",
    "with open(FILE_NAME, 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3cd242-7b52-4e31-b0d3-08e9b68027d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train/Valid Loss History\n",
    "plot_from = 0\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Train/Valid Loss History\", fontsize = 20)\n",
    "plt.plot(\n",
    "    range(0, len(result['Train Loss'][plot_from:])), \n",
    "    result['Train Loss'][plot_from:], \n",
    "    label = 'Train Loss'\n",
    "    )\n",
    "\n",
    "plt.plot(\n",
    "    range(0, len(result['Valid Loss'][plot_from:])), \n",
    "    result['Valid Loss'][plot_from:], \n",
    "    label = 'Valid Loss'\n",
    "    )\n",
    "\n",
    "plt.legend()\n",
    "# plt.yscale('log')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8054fe76-b434-423c-b01a-45c883914795",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train/Valid Accuracy History\n",
    "plot_from = 0\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Train/Valid Accuracy History\", fontsize = 20)\n",
    "plt.plot(\n",
    "    range(0, len(result['Train Accuracy'][plot_from:])), \n",
    "    result['Train Accuracy'][plot_from:], \n",
    "    label = 'Train Accuracy'\n",
    "    )\n",
    "\n",
    "plt.plot(\n",
    "    range(0, len(result['Valid Accuracy'][plot_from:])), \n",
    "    result['Valid Accuracy'][plot_from:], \n",
    "    label = 'Valid Accuracy'\n",
    "    )\n",
    "\n",
    "plt.legend()\n",
    "# plt.yscale('log')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc4374d-2857-4de1-a89a-82b3c4c24a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6decf867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
